#!/usr/bin/env python3
"""
ArXiv LLM Research Toolkit
–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ —Ç–∞ summarization AI/ML —Å—Ç–∞—Ç–µ–π –∑ arXiv
"""

from arxiv_llm_scraper import ArxivLLMScraper
from datetime import datetime
import json
import os
import argparse

def main():
    parser = argparse.ArgumentParser(
        description='üî¨ ArXiv LLM Research Toolkit - Search and summarize AI papers',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # --- –ê—Ä–≥—É–º–µ–Ω—Ç–∏ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –±–µ–∑ –∑–º—ñ–Ω ---
    parser.add_argument('--start-date', type=str, default='2025-09-25', help='Start date in YYYY-MM-DD format (default: 2025-09-25)')
    parser.add_argument('--end-date', type=str, default=datetime.now().strftime('%Y-%m-%d'), help='End date in YYYY-MM-DD format (default: today)')
    parser.add_argument('--max-results', type=int, default=200, help='Maximum number of results to fetch (default: 200)')
    parser.add_argument('--use-llm', action='store_true', help='Use LLM for summarization (requires OpenAI API key)')
    parser.add_argument('--output-json', type=str, default='results.json', help='JSON output filename (default: results.json)')
    parser.add_argument('--output-csv', type=str, default='results.csv', help='CSV output filename (default: results.csv)')
    parser.add_argument('--output-md', type=str, default='report.md', help='Markdown report filename (default: report.md)')
    
    args = parser.parse_args()
    
    # --- –õ–æ–≥—ñ–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ —É –ø–∞–ø–∫—É 'results' ---

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–∞–∑–≤—É –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    output_dir = "results"
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É, —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ —ñ—Å–Ω—É—î. exist_ok=True –∑–∞–ø–æ–±—ñ–≥–∞—î –ø–æ–º–∏–ª—Ü—ñ, —è–∫—â–æ –ø–∞–ø–∫–∞ –≤–∂–µ —î.
    os.makedirs(output_dir, exist_ok=True)

    # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω—ñ —à–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤, –¥–æ–¥–∞—é—á–∏ —ñ–º'—è –ø–∞–ø–∫–∏
    json_path = os.path.join(output_dir, args.output_json)
    csv_path = os.path.join(output_dir, args.output_csv)
    md_path = os.path.join(output_dir, args.output_md)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–∞—Ç
    start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
    end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
    
    print("=" * 60)
    print("ü§ñ ArXiv LLM Research Toolkit")
    print("=" * 60)
    print(f"üìÖ Period: {args.start_date} to {args.end_date}")
    print(f"üìä Max results: {args.max_results}")
    print(f"ü§ñ LLM Summarization: {'Enabled' if args.use_llm else 'Disabled'}")
    print("=" * 60)
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–∏—Ö —Å—Ç–∞—Ç–µ–π
    old_papers = []
    existing_ids = set()
    if os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                old_papers = json.load(f)
                existing_ids = {paper['pdf_url'] for paper in old_papers}
            print(f"üìñ Loaded {len(old_papers)} previously saved papers.")
        except (json.JSONDecodeError, IOError) as e:
            print(f"‚ö†Ô∏è Could not read {json_path}. Starting fresh. Error: {e}")
    
    # –ü–æ—à—É–∫ –Ω–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π
    scraper = ArxivLLMScraper()
    new_papers = scraper.search_papers(
        start_date=start_date,
        end_date=end_date,
        max_results=args.max_results,
        existing_ids=existing_ids,
        use_llm=args.use_llm
    )
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    if new_papers:
        all_papers = old_papers + new_papers
        
        print(f"\nüíæ Total papers in database: {len(all_papers)}. Updating files...")
        
        scraper.save_to_csv(all_papers, csv_path)
        scraper.save_to_json(all_papers, json_path)
        scraper.save_to_markdown(all_papers, md_path)
        
        print(f"\n‚úÖ Successfully added {len(new_papers)} new papers!")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if args.use_llm:
            print(f"ü§ñ AI summaries generated: {len([p for p in new_papers if p.get('ai_summary')])}")
    else:
        print("\n‚úÖ No new papers found for the specified period.")
    
    # –í–∏–≤—ñ–¥ —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
    print("\n" + "=" * 60)
    print("üìÅ Output files:")
    print(f"  - {json_path}")
    print(f"  - {csv_path}")
    print(f"  - {md_path}")
    print("=" * 60)

if __name__ == "__main__":
    main()