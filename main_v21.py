#!/usr/bin/env python3
"""
ArXiv LLM Research Toolkit v2.1
ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð¿Ð¾ÑˆÑƒÐº Ñ‚Ð° summarization AI/ML ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð· arXiv
ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ” v2.0 (Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð°Ð³ÐµÐ½Ñ‚Ð°Ñ…) Ñ‚Ð° v2.1 (Ð²ÑÑ LLM ÐµÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð°)
"""

from datetime import datetime
import json
import os
import argparse

def main():
    parser = argparse.ArgumentParser(
        description='ðŸ”¬ ArXiv LLM Research Toolkit v2.1 - Search and summarize AI papers',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:
  # Ð‘Ð°Ð·Ð¾Ð²Ð¸Ð¹ Ð·Ð°Ð¿ÑƒÑÐº (v2.1, Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– 6 Ð¼Ñ–ÑÑÑ†Ñ–Ð²)
  python main_v21.py
  
  # Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ v2.0 (Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð°Ð³ÐµÐ½Ñ‚Ð°Ñ…)
  python main_v21.py --version 2.0
  
  # ÐšÐ°ÑÑ‚Ð¾Ð¼Ð½Ð¸Ð¹ Ð¿ÐµÑ€Ñ–Ð¾Ð´ Ð· LLM ÑÐ°Ð¼Ð¼Ð°Ñ€Ñ–
  python main_v21.py --start-date 2025-01-01 --use-llm
  
  # Ð‘Ñ–Ð»ÑŒÑˆÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²
  python main_v21.py --max-results 500 --top-llm 100
        """
    )
    
    # === ÐÐžÐ’Ð˜Ð™ ÐŸÐÐ ÐÐœÐ•Ð¢Ð : Ð’Ð¸Ð±Ñ–Ñ€ Ð²ÐµÑ€ÑÑ–Ñ— ===
    parser.add_argument('--version', type=str, default='2.1', choices=['2.0', '2.1'],
                       help='Scraper version: 2.0 (agents focus) or 2.1 (full LLM ecosystem, default)')
    
    # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð´Ð°Ñ‚
    parser.add_argument('--start-date', type=str, 
                       default=(datetime.now().replace(month=datetime.now().month-6 if datetime.now().month > 6 else datetime.now().month+6, 
                                                       year=datetime.now().year if datetime.now().month > 6 else datetime.now().year-1)).strftime('%Y-%m-%d'),
                       help='Start date in YYYY-MM-DD format (default: 6 months ago)')
    parser.add_argument('--end-date', type=str, 
                       default=datetime.now().strftime('%Y-%m-%d'), 
                       help='End date in YYYY-MM-DD format (default: today)')
    
    # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð¿Ð¾ÑˆÑƒÐºÑƒ
    parser.add_argument('--max-results', type=int, default=300, 
                       help='Maximum papers to fetch from ArXiv (default: 300)')
    parser.add_argument('--min-score', type=int, default=20,
                       help='Minimum keyword score to pass Stage 1 (default: 40)')
    parser.add_argument('--top-citations', type=int, default=100,
                       help='Top N papers to get citations for (Stage 2, default: 100)')
    parser.add_argument('--top-llm', type=int, default=50,
                       help='Top N papers to evaluate with LLM (Stage 3, default: 50)')
    parser.add_argument('--final-top', type=int, default=30,
                       help='Final number of papers to save (default: 30)')
    
    # LLM Ð¾Ð¿Ñ†Ñ–Ñ—
    parser.add_argument('--use-llm', action='store_true', 
                       help='Enable LLM evaluation (Stage 3)')
    parser.add_argument('--no-llm', action='store_true',
                       help='Disable LLM evaluation (budget mode, $0)')
    parser.add_argument('--generate-summaries', action='store_true',
                       help='Generate AI summaries for all papers (costs extra)')
    
    # Ð’Ð¸Ñ…Ñ–Ð´Ð½Ñ– Ñ„Ð°Ð¹Ð»Ð¸
    parser.add_argument('--output-dir', type=str, default='results',
                       help='Output directory (default: results)')
    parser.add_argument('--output-prefix', type=str, default='papers',
                       help='Prefix for output files (default: papers)')
    
    args = parser.parse_args()
    
    # === Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ñ— Ð²ÐµÑ€ÑÑ–Ñ— ===
    if args.version == '2.1':
        try:
            from arxiv_llm_scraper_hybrid_v21 import ArxivLLMScraperHybrid
            version_name = "v2.1 (Full LLM Ecosystem)"
        except ImportError:
            print("âš ï¸ v2.1 not found, falling back to v2.0")
            from arxiv_llm_scraper_hybrid import ArxivLLMScraperHybrid
            version_name = "v2.0 (Agents Focus)"
    else:
        from arxiv_llm_scraper_hybrid import ArxivLLMScraperHybrid
        version_name = "v2.0 (Agents Focus)"
    
    # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ output Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Ð“ÐµÐ½ÐµÑ€ÑƒÑ”Ð¼Ð¾ Ñ–Ð¼ÐµÐ½Ð° Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð· timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    version_suffix = args.version.replace('.', '')
    json_path = os.path.join(args.output_dir, f"{args.output_prefix}_v{version_suffix}_{timestamp}.json")
    csv_path = os.path.join(args.output_dir, f"{args.output_prefix}_v{version_suffix}_{timestamp}.csv")
    md_path = os.path.join(args.output_dir, f"{args.output_prefix}_v{version_suffix}_{timestamp}.md")
    
    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ñ–Ñ Ð´Ð°Ñ‚
    try:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d')
        end_date = datetime.strptime(args.end_date, '%Y-%m-%d')
    except ValueError as e:
        print(f"âŒ Invalid date format: {e}")
        print("Use YYYY-MM-DD format (e.g., 2025-01-01)")
        return
    
    # Ð’Ð¸Ð·Ð½Ð°Ñ‡Ð°Ñ”Ð¼Ð¾ Ñ‡Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ LLM
    use_llm = args.use_llm or not args.no_llm  # Ð—Ð° Ð·Ð°Ð¼Ð¾Ð²Ñ‡ÑƒÐ²Ð°Ð½Ð½ÑÐ¼ LLM enabled
    if args.no_llm:
        args.top_llm = 0  # Budget mode
    
    # === ÐšÑ€Ð°ÑÐ¸Ð²Ð¸Ð¹ Ð²Ð¸Ð²Ñ–Ð´ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ–Ð² ===
    print("\n" + "=" * 70)
    print("ðŸš€ ArXiv LLM Research Toolkit v2.1")
    print("=" * 70)
    print(f"ðŸ“Œ Version:          {version_name}")
    print(f"ðŸ“… Period:           {args.start_date} to {args.end_date}")
    print(f"ðŸ” Max results:      {args.max_results} papers")
    print(f"ðŸ“Š Min keyword score: {args.min_score}")
    print()
    print("ðŸŽ¯ Pipeline Configuration:")
    print(f"   Stage 1 (Keywords):  All papers â†’ filter by score >= {args.min_score}")
    print(f"   Stage 2 (Citations): Top {args.top_citations} papers")
    print(f"   Stage 3 (LLM):       {'Top ' + str(args.top_llm) + ' papers' if args.top_llm > 0 else 'DISABLED (Budget Mode)'}")
    print(f"   Final output:        Top {args.final_top} papers")
    print()
    print(f"ðŸ¤– LLM Features:")
    print(f"   Evaluation:      {'âœ… Enabled' if use_llm and args.top_llm > 0 else 'âŒ Disabled'}")
    print(f"   AI Summaries:    {'âœ… Enabled' if args.generate_summaries else 'âŒ Disabled'}")
    print()
    print(f"ðŸ’° Estimated cost:   ${estimate_cost(args.top_llm, args.generate_summaries, args.final_top)}")
    print("=" * 70 + "\n")
    
    # === ÐŸÐ¾ÑˆÑƒÐº ÑÑ‚Ð°Ñ‚ÐµÐ¹ ===
    scraper = ArxivLLMScraperHybrid()
    
    try:
        papers = scraper.search_papers(
            start_date=start_date,
            end_date=end_date,
            max_results=args.max_results,
            min_keyword_score=args.min_score,
            top_n_for_citations=args.top_citations,
            top_n_for_llm=args.top_llm,
            final_top_n=args.final_top
        )
    except Exception as e:
        print(f"\nâŒ Error during search: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # === Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð² ===
    if papers:
        print(f"\n{'='*70}")
        print(f"ðŸ’¾ Saving results...")
        print(f"{'='*70}\n")
        
        try:
            scraper.save_to_json(papers, json_path)
            scraper.save_to_csv(papers, csv_path)
            scraper.save_to_markdown(papers, md_path, generate_summaries=args.generate_summaries)
            
            print(f"\n{'='*70}")
            print("âœ… SUCCESS! Papers saved to:")
            print(f"{'='*70}")
            print(f"  ðŸ“„ JSON:     {json_path}")
            print(f"  ðŸ“Š CSV:      {csv_path}")
            print(f"  ðŸ“– Markdown: {md_path}")
            print(f"{'='*70}\n")
            
            # === Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ===
            print_statistics(papers, args.version)
            
        except Exception as e:
            print(f"\nâŒ Error saving files: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("\nâš ï¸ No papers found matching the criteria.")
        print("Try:")
        print("  - Lowering --min-score (default: 40)")
        print("  - Increasing --max-results (default: 300)")
        print("  - Expanding date range")


def estimate_cost(top_llm, generate_summaries, final_top):
    """ÐžÑ†Ñ–Ð½ÐºÐ° Ð²Ð°Ñ€Ñ‚Ð¾ÑÑ‚Ñ– OpenAI API"""
    if top_llm == 0:
        return "0.00 (Budget Mode)"
    
    cost = 0.0
    
    # LLM evaluation (~100 tokens per paper)
    if top_llm > 0:
        cost += (top_llm * 100 * 0.00000015)  # GPT-4o-mini input
        cost += (top_llm * 50 * 0.0000006)    # GPT-4o-mini output
    
    # AI summaries (~150 tokens per paper)
    if generate_summaries:
        cost += (final_top * 800 * 0.00000015)  # input (abstract)
        cost += (final_top * 150 * 0.0000006)   # output (summary)
    
    return f"{cost:.4f}"


def print_statistics(papers, version):
    """Ð’Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¸Ñ… ÑÑ‚Ð°Ñ‚Ñ‚ÑÑ…"""
    print("ðŸ“Š STATISTICS")
    print("=" * 70)
    print(f"Total papers found:  {len(papers)}")
    
    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÑ…
    categories_count = {}
    for paper in papers:
        cats = paper.get('categories', 'Unknown').split(' | ')
        for cat in cats:
            categories_count[cat] = categories_count.get(cat, 0) + 1
    
    print(f"\nTop Categories:")
    for cat, count in sorted(categories_count.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"  {cat}: {count} papers")
    
    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ scores
    avg_keyword = sum(p.get('keyword_score', 0) for p in papers) / len(papers) if papers else 0
    avg_citations = sum(p.get('citations', 0) for p in papers) / len(papers) if papers else 0
    avg_llm = sum(p.get('llm_score', 0) for p in papers if p.get('llm_score', 0) > 0)
    llm_count = len([p for p in papers if p.get('llm_score', 0) > 0])
    avg_llm = avg_llm / llm_count if llm_count > 0 else 0
    
    print(f"\nAverage Scores:")
    print(f"  Keyword Score:  {avg_keyword:.1f}")
    print(f"  Citations:      {avg_citations:.1f}")
    if avg_llm > 0:
        print(f"  LLM Score:      {avg_llm:.1f}")
    
    # Ð¢Ð¾Ð¿ ÑÑ‚Ð°Ñ‚Ñ‚Ñ–
    print(f"\nðŸ† Top 3 Papers:")
    for i, paper in enumerate(papers[:3], 1):
        print(f"\n  {i}. [{paper.get('final_score', 0)}] {paper['title'][:65]}...")
        print(f"     {paper.get('categories', 'N/A')}")
        if paper.get('llm_reason'):
            print(f"     ðŸ’­ {paper['llm_reason'][:60]}...")
    
    print("\n" + "=" * 70)


def show_version_comparison():
    """ÐŸÐ¾ÐºÐ°Ð·ÑƒÑ” Ð¿Ð¾Ñ€Ñ–Ð²Ð½ÑÐ½Ð½Ñ Ð²ÐµÑ€ÑÑ–Ð¹"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              VERSION COMPARISON: v2.0 vs v2.1                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

v2.0 - Agents Focus:
  âœ“ 70 keywords
  âœ“ Strong focus on AI agents
  âœ“ 7 categories
  âœ“ Good for agent-specific research

v2.1 - Full LLM Ecosystem (RECOMMENDED):
  âœ“ 150+ keywords (+114%)
  âœ“ Balanced focus on entire LLM ecosystem
  âœ“ 12 categories (+71%)
  âœ“ Covers: prompting, new models, context, capabilities
  âœ“ 2-3x more relevant papers found

Recommendation: Use v2.1 for most cases!
Use v2.0 only if you need ONLY agent papers.
    """)


if __name__ == "__main__":
    # Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ ÑÐ¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--compare':
        show_version_comparison()
        sys.exit(0)
    
    main()
